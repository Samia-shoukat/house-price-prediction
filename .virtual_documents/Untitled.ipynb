import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn import metrics
from xgboost import XGBRegressor


house_price_dataset = sklearn.datasets.fetch_california_housing()



# convert into df
df = pd.DataFrame(house_price_dataset.data, columns=house_price.feature_names)


print(df.head())


# add the target (price) col to df
df["price"] = house_price_dataset.target


print(df.head())


df.shape


# check missing values
df.isnull().sum()


# statistical measure of the data
df.describe()





correlation = df.corr()

plt.figure(figsize=(10, 10))
sns.heatmap(
    correlation,
    cbar=True,
    square=True,
    fmt='.1f',                 
    annot=True,
    annot_kws={'size': 8},
    cmap='Blues'
)
plt.show()
plt.show()


X = df.drop(['price'],axis=1)
Y = df['price']


print(X)
print(Y)


# splitting the data into train-test
X_train, X_test, Y_train , Y_test = train_test_split(X, Y ,test_size=0.2, random_state=2)



print(X.shape,X_train.shape,X_test.shape)


# Train Model
model = XGBRegressor()


model.fit(X_train, Y_train)


# accuracy for prediction on training data
training_data_prediction = model.predict(X_train)


print(training_data_prediction)


# RSE
score_1 = metrics.r2_score(Y_train,training_data_prediction)

# MAE
score_2 = metrics.mean_absolute_error(Y_train,training_data_prediction)

print("R squared Error", score_1)
print("Mean Absolute Error", score_2)


# visualize the actual and predicted data
plt.scatter(Y_train,training_data_prediction)
plt.xlabel("Actual price")
plt.ylabel("Predicted price")
plt.title("Actualprice vs predicted price")
plt.show()


# Prediction on test data
test_data_prediction = model.predict(X_test)
# RSE
score_1 = metrics.r2_score(Y_test,test_data_prediction)

# MAE
score_2 = metrics.mean_absolute_error(Y_test,test_data_prediction)

print("R squared Error", score_1)
print("Mean Absolute Error", score_2)



